{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Our Essential Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the probability a student will \"pass the class(1)\"\n",
    "def predict(features, weights, bias):\n",
    "    \n",
    "    x = np.dot(features, weights) \n",
    "    z = x + bias\n",
    "    # sigmoid activation function to represent our probabilities:\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def classify(predictions):\n",
    "    \n",
    "    df = pd.DataFrame(predictions)\n",
    "    df[0] = df[0].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "    predictions = df.to_numpy()\n",
    "    \n",
    "    return predictions\n",
    "    \n",
    "def update_weights(features, targets, weights, bias, learning_rate):\n",
    "    \n",
    "    N = len(features)\n",
    "        \n",
    "    # make predictions\n",
    "    predictions = predict(features, weights, bias)\n",
    "        \n",
    "    # formula for updating weights from the derivative of the cost function with respect to weights:\n",
    "    # new_weights = original_weights + learning_rate(ytrue - ypred)(input)\n",
    "    \n",
    "    # the derivative of the cost function with respect to weights:\n",
    "    # we also need to transpose the feature matrix so we can use it in multiplication with the other matrix:\n",
    "    gradient = np.dot(features.T, targets - predictions)\n",
    "    \n",
    "    # take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    # multiply the gradient by our learning rate\n",
    "    gradient *= learning_rate\n",
    "   \n",
    "    # add to our weights to minimize cost\n",
    "    weights += gradient\n",
    "\n",
    "    return weights\n",
    "    \n",
    "def update_bias(features, targets, weights, bias, learning_rate):\n",
    "    \n",
    "    N = len(features)\n",
    "        \n",
    "    # we use the same update function as update_weights except we assume input is always 1\n",
    "    # new_bias = original_bias + learning_rate(ytrue - ypred)(input)\n",
    "    predictions = predict(features, weights, bias)\n",
    "    \n",
    "    # the derivative of the cost function with respect to weights and input of 1:\n",
    "    gradient = np.dot(learning_rate,  targets - predictions)\n",
    "\n",
    "    # average cost derivative for each feature:\n",
    "    gradient /= N\n",
    "\n",
    "    # add to our bias to minimize cost\n",
    "    bias += gradient\n",
    "  \n",
    "    return bias\n",
    "\n",
    "# cross entropy cost function:\n",
    "def cost_function(features, targets, weights, bias):\n",
    "    \n",
    "    N = len(features)\n",
    "    \n",
    "    predictions = predict(features, weights, bias)\n",
    "    \n",
    "    # Error when target=1\n",
    "    cost1 = -targets*np.log(predictions)\n",
    "\n",
    "    # Error when target=0\n",
    "    cost2 = (1-targets)*np.log(1-predictions)\n",
    "\n",
    "    # Sum of both costs\n",
    "    cost = cost1 - cost2\n",
    "\n",
    "    # Average cost\n",
    "    cost = cost.sum() / N\n",
    "\n",
    "    return cost\n",
    "\n",
    "# Keeping track of our loss:\n",
    "cost_history = []\n",
    "\n",
    "def train(features, targets, weights, bias, learning_rate, iters):\n",
    "    \n",
    "    # using gradient descent because of small dataset:\n",
    "    for i in range(iters):\n",
    "        \n",
    "        weights = update_weights(features, targets, weights, bias, learning_rate)\n",
    "        bias = update_bias(features, targets, weights, bias, learning_rate)\n",
    "\n",
    "        #Calculate error for auditing purposes:\n",
    "        cost = cost_function(features, targets, weights, bias)\n",
    "\n",
    "        # Keeping track of our loss:\n",
    "        if i % 100 == 0:\n",
    "            cost_history.append([i,cost])\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "# Find accuracy of our model:\n",
    "def accuracy(predicted_labels, actual_labels):\n",
    "    \n",
    "    diff = predicted_labels - actual_labels\n",
    "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Our Model\n",
    "- Here we define our targets and features after cleaning the data and shape the matrices to our desired shape\n",
    "- We also do the same for our weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the final dataframe from Data_Cleaning script\n",
    "from ipynb.fs.full.Data_Cleaning import df\n",
    "\n",
    "# creating targets and features\n",
    "targets = df['G3'].to_numpy().reshape(395,1)\n",
    "df = df.drop('G3', axis=1)\n",
    "features = df.to_numpy() # shape: (395, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our variables:\n",
    "weights = np.zeros( shape=(23,1) )\n",
    "bias = np.ones( shape=(197,1) )\n",
    "learning_rate = 0.01\n",
    "iters = 5000\n",
    "\n",
    "# features[:197], targets[:197] will be our training set\n",
    "\n",
    "# obtain optimal weights and bias:\n",
    "weights, bias = train(features[:197], targets[:197], weights, bias, learning_rate, iters)\n",
    "\n",
    "# make predictions:\n",
    "predictions = predict(features[198:], weights, bias)\n",
    "\n",
    "# Uncomment to see probability predictions:\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6091370558375635"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the model accuracy:\n",
    "\n",
    "predicted = classify(predictions)\n",
    "accuracy(predicted, targets[198:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Our Cross Entropy Loss Function\n",
    "- We can achieve nearly zero loss if we run enough iters but the problem is that it will be too overfit to the training dataset causing a lower accuracy in predicting newer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(cost_history)):\n",
    "    \n",
    "    plt.ylim((0,1))\n",
    "    plt.xlim((0,iters))\n",
    "    plt.scatter(cost_history[i][0], cost_history[i][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
