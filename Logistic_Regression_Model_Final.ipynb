{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Logistic Regression Model \n",
    "- some of the code is based on this resource here: https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html#binary-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Our Essential Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(features, targets, weights, bias, learning_rate):\n",
    "    \n",
    "    N = len(features)\n",
    "        \n",
    "    # make predictions\n",
    "    predictions = predict(features, weights, bias)\n",
    "        \n",
    "    # formula for updating weights from the derivative of the cost function with respect to weights:\n",
    "    # new_weights = original_weights + learning_rate(ytrue - ypred)(input)\n",
    "    \n",
    "    # the derivative of the cost function with respect to weights:\n",
    "    # we also need to transpose the feature matrix so we can use it in multiplication with the other matrix:\n",
    "    gradient = np.dot(features.T, targets - predictions)\n",
    "    \n",
    "    # take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    # multiply the gradient by our learning rate\n",
    "    gradient *= learning_rate\n",
    "   \n",
    "    # add to our weights to minimize cost\n",
    "    weights += gradient\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the probability a student will \"pass the class(1)\"\n",
    "def predict(features, weights, bias):\n",
    "    \n",
    "    x = np.dot(features, weights) \n",
    "    z = x + bias\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bias(features, targets, weights, bias, learning_rate):\n",
    "    \n",
    "    N = len(features)\n",
    "        \n",
    "    # we use the same update function as update_weights except we assume input is always 1\n",
    "    # new_bias = original_bias + learning_rate(ytrue - ypred)(input)\n",
    "    predictions = predict(features, weights, bias)\n",
    "    \n",
    "    # the derivative of the cost function with respect to weights and input of 1:\n",
    "    gradient = np.dot(learning_rate,  targets - predictions)\n",
    "\n",
    "    # add to our bias to minimize cost\n",
    "    bias = np.add(bias, gradient)\n",
    "  \n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(predictions):\n",
    "    \n",
    "    df = pd.DataFrame(predictions)\n",
    "    df[0] = df[0].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "    predictions = df.to_numpy()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# cross entropy cost function:\n",
    "def cost_function(features, targets, weights, bias):\n",
    "    \n",
    "    N = len(features)\n",
    "    \n",
    "    predictions = predict(features, weights, bias)\n",
    "    \n",
    "    # Error when target=1\n",
    "    cost1 = -targets*np.log(predictions)\n",
    "\n",
    "    # Error when target=0\n",
    "    cost2 = (1-targets)*np.log(1-predictions)\n",
    "\n",
    "    # Sum of both costs\n",
    "    cost = cost1 - cost2\n",
    "\n",
    "    # Average cost\n",
    "    cost = cost.sum() / N\n",
    "\n",
    "    return cost\n",
    "\n",
    "# Keeping track of our loss:\n",
    "cost_history = []\n",
    "\n",
    "def train(features, targets, weights, bias, learning_rate, iters):\n",
    "    \n",
    "    # using gradient descent because of small dataset:\n",
    "    for i in range(iters):\n",
    "        \n",
    "        weights = update_weights(features, targets, weights, bias, learning_rate)\n",
    "        bias = update_bias(features, targets, weights, bias, learning_rate)\n",
    "\n",
    "        #Calculate error for auditing purposes:\n",
    "        cost = cost_function(features, targets, weights, bias)\n",
    "\n",
    "        # Keeping track of our loss:\n",
    "        if i % 100 == 0:\n",
    "            cost_history.append([i,cost])\n",
    "\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Our Model\n",
    "- Here we define our targets and features after cleaning the data and shape the matrices to our desired shape\n",
    "- We also do the same for our weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the final dataframe from Data_Cleaning script\n",
    "from ipynb.fs.full.Data_Cleaning import df\n",
    "\n",
    "# creating targets and features\n",
    "targets = df['G3'].to_numpy().reshape(395,1)\n",
    "df = df.drop('G3', axis=1)\n",
    "features = df.to_numpy() # shape: (395, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features[:300]\n",
    "y_train = targets[:300]\n",
    "X_test = features[300:]\n",
    "y_test = targets[300:]\n",
    "\n",
    "\n",
    "# defining our variables:\n",
    "weights = np.zeros( shape=(23,1) )\n",
    "bias = np.ones( shape=(X_train.shape[0],1) )\n",
    "learning_rate = 0.01\n",
    "iters = 1000\n",
    "\n",
    "\n",
    "weights, bias = train(X_train, y_train, weights, bias, learning_rate, iters)\n",
    "\n",
    "# taking the average bias so that we can use for predictions:\n",
    "bias = np.array([bias.mean()])\n",
    "\n",
    "predictions = predict(X_test, weights, bias)\n",
    "\n",
    "# # Uncomment to see probability predictions:\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6105263157894737\n"
     ]
    }
   ],
   "source": [
    "# finding the model accuracy:\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predicted = classify(predictions)\n",
    "\n",
    "correct = accuracy_score(y_test, predicted)\n",
    "print(f\"Accuracy: {correct}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Our Cross Entropy Loss Function During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for i in range(len(cost_history)):\n",
    "    \n",
    "    plt.ylim((0,1))\n",
    "    plt.xlim((0,iters))\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.scatter(cost_history[i][0], cost_history[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Part\n",
    "- below is some example data that can inputted with the optimized weights and bias\n",
    "- refer to data cleaning script for more information on what each index means\n",
    "- link to dataset: https://www.kaggle.com/uciml/student-alcohol-consumption\n",
    "- each index in the input correlates with the column of the dataframe\n",
    "- tweak the input and see what results you get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "your_data = np.array( [1, 1, 0, 5, 4, 2, 2, 0, 1, 1, 0, 1, 1, 1, 0, 0, 4, 3, 4, 1, 1, 3, 6] ).reshape(1,23)\n",
    "\n",
    "pred = predict(your_data, weights, bias)\n",
    "\n",
    "predicted = classify(pred)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>...</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     address  famsize  Pstatus  Medu  Fedu  traveltime  studytime  failures  \\\n",
       "0          1        1        0     4     4           2          2         0   \n",
       "1          1        1        1     1     1           1          2         0   \n",
       "2          1        0        1     1     1           1          2         3   \n",
       "3          1        1        1     4     2           1          3         0   \n",
       "4          1        1        1     3     3           1          2         0   \n",
       "..       ...      ...      ...   ...   ...         ...        ...       ...   \n",
       "390        1        0        0     2     2           1          2         2   \n",
       "391        1        0        1     3     1           2          1         0   \n",
       "392        0        1        1     1     1           1          1         3   \n",
       "393        0        0        1     3     2           3          1         0   \n",
       "394        1        0        1     1     1           1          1         0   \n",
       "\n",
       "     schoolsup  famsup  ...  higher  internet  romantic  famrel  freetime  \\\n",
       "0            1       0  ...       1         0         0       4         3   \n",
       "1            0       1  ...       1         1         0       5         3   \n",
       "2            1       0  ...       1         1         0       4         3   \n",
       "3            0       1  ...       1         1         1       3         2   \n",
       "4            0       1  ...       1         0         0       4         3   \n",
       "..         ...     ...  ...     ...       ...       ...     ...       ...   \n",
       "390          0       1  ...       1         0         0       5         5   \n",
       "391          0       0  ...       1         1         0       2         4   \n",
       "392          0       0  ...       1         0         0       5         5   \n",
       "393          0       0  ...       1         1         0       4         4   \n",
       "394          0       0  ...       1         1         0       3         2   \n",
       "\n",
       "     goout  Dalc  Walc  health  absences  \n",
       "0        4     1     1       3         6  \n",
       "1        3     1     1       3         4  \n",
       "2        2     2     3       3        10  \n",
       "3        2     1     1       5         2  \n",
       "4        2     1     2       5         4  \n",
       "..     ...   ...   ...     ...       ...  \n",
       "390      4     4     5       4        11  \n",
       "391      5     3     4       2         3  \n",
       "392      3     3     3       3         3  \n",
       "393      1     3     4       5         0  \n",
       "394      3     3     3       5         5  \n",
       "\n",
       "[395 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
