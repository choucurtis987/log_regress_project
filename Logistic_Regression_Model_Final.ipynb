{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Our Essential Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(features, targets, weights, bias, learning_rate):\n",
    "    \n",
    "    N = len(features)\n",
    "        \n",
    "    # make predictions\n",
    "    predictions = predict(features, weights, bias)\n",
    "        \n",
    "    # formula for updating weights from the derivative of the cost function with respect to weights:\n",
    "    # new_weights = original_weights + learning_rate(ytrue - ypred)(input)\n",
    "    \n",
    "    # the derivative of the cost function with respect to weights:\n",
    "    # we also need to transpose the feature matrix so we can use it in multiplication with the other matrix:\n",
    "    gradient = np.dot(features.T, targets - predictions)\n",
    "    \n",
    "    # take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    # multiply the gradient by our learning rate\n",
    "    gradient *= learning_rate\n",
    "   \n",
    "    # add to our weights to minimize cost\n",
    "    weights += gradient\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the probability a student will \"pass the class(1)\"\n",
    "def predict(features, weights, bias):\n",
    "    \n",
    "    x = np.dot(features, weights) \n",
    "    z = x + bias\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bias(features, targets, weights, bias, learning_rate):\n",
    "    \n",
    "    N = len(features)\n",
    "        \n",
    "    # we use the same update function as update_weights except we assume input is always 1\n",
    "    # new_bias = original_bias + learning_rate(ytrue - ypred)(input)\n",
    "    predictions = predict(features, weights, bias)\n",
    "    \n",
    "    # the derivative of the cost function with respect to weights and input of 1:\n",
    "    gradient = np.dot(learning_rate,  targets - predictions)\n",
    "\n",
    "    # average gradient for bias:\n",
    "    gradient = np.mean(gradient)\n",
    "\n",
    "    # add to our bias to minimize cost\n",
    "    bias = np.add(bias, gradient)\n",
    "  \n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(predictions):\n",
    "    \n",
    "    df = pd.DataFrame(predictions)\n",
    "    df[0] = df[0].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "    predictions = df.to_numpy()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# cross entropy cost function:\n",
    "def cost_function(features, targets, weights, bias):\n",
    "    \n",
    "    N = len(features)\n",
    "    \n",
    "    predictions = predict(features, weights, bias)\n",
    "    \n",
    "    # Error when target=1\n",
    "    cost1 = -targets*np.log(predictions)\n",
    "\n",
    "    # Error when target=0\n",
    "    cost2 = (1-targets)*np.log(1-predictions)\n",
    "\n",
    "    # Sum of both costs\n",
    "    cost = cost1 - cost2\n",
    "\n",
    "    # Average cost\n",
    "    cost = cost.sum() / N\n",
    "\n",
    "    return cost\n",
    "\n",
    "# Keeping track of our loss:\n",
    "cost_history = []\n",
    "\n",
    "def train(features, targets, weights, bias, learning_rate, iters):\n",
    "    \n",
    "    # using gradient descent because of small dataset:\n",
    "    for i in range(iters):\n",
    "        \n",
    "        weights = update_weights(features, targets, weights, bias, learning_rate)\n",
    "        bias = update_bias(features, targets, weights, bias, learning_rate)\n",
    "\n",
    "        #Calculate error for auditing purposes:\n",
    "        cost = cost_function(features, targets, weights, bias)\n",
    "\n",
    "        # Keeping track of our loss:\n",
    "        if i % 1000 == 0:\n",
    "            cost_history.append([i,cost])\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "# Find accuracy of our model:\n",
    "def accuracy(predicted_labels, actual_labels):\n",
    "    \n",
    "    diff = predicted_labels - actual_labels\n",
    "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Our Model\n",
    "- Here we define our targets and features after cleaning the data and shape the matrices to our desired shape\n",
    "- We also do the same for our weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the final dataframe from Data_Cleaning script\n",
    "from ipynb.fs.full.Data_Cleaning import df\n",
    "\n",
    "# creating targets and features\n",
    "targets = df['G3'].to_numpy().reshape(395,1)\n",
    "df = df.drop('G3', axis=1)\n",
    "features = df.to_numpy() # shape: (395, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our variables:\n",
    "weights = np.zeros( shape=(23,1) )\n",
    "bias = np.array([1])\n",
    "learning_rate = 0.01\n",
    "iters = 10000\n",
    "\n",
    "\n",
    "weights, bias = train(features[:300], targets[:300], weights, bias, learning_rate, iters)\n",
    "\n",
    "predictions = predict(features[300:], weights, bias)\n",
    "\n",
    "# # Uncomment to see probability predictions:\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the model accuracy:\n",
    "predicted = classify(predictions)\n",
    "accuracy(predicted, targets[300:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Our Cross Entropy Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(cost_history)):\n",
    "    \n",
    "    plt.ylim((0,1))\n",
    "    plt.xlim((0,iters))\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.scatter(cost_history[i][0], cost_history[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Part\n",
    "- below is some example data that can inputted with the optimized weights and bias\n",
    "- each index in the input correlates with the column of the dataframe\n",
    "- tweak the input and see what results you get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "your_data = np.array( [1, 1, 0, 5, 4, 2, 2, 0, 1, 1, 0, 1, 1, 1, 0, 0, 4, 3, 4, 1, 1, 3, 6] ).reshape(1,23)\n",
    "\n",
    "pred = predict(your_data, weights, bias)\n",
    "\n",
    "predicted = classify(pred)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>...</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     address  famsize  Pstatus  Medu  Fedu  traveltime  studytime  failures  \\\n",
       "0          1        1        0     4     4           2          2         0   \n",
       "1          1        1        1     1     1           1          2         0   \n",
       "2          1        0        1     1     1           1          2         3   \n",
       "3          1        1        1     4     2           1          3         0   \n",
       "4          1        1        1     3     3           1          2         0   \n",
       "..       ...      ...      ...   ...   ...         ...        ...       ...   \n",
       "390        1        0        0     2     2           1          2         2   \n",
       "391        1        0        1     3     1           2          1         0   \n",
       "392        0        1        1     1     1           1          1         3   \n",
       "393        0        0        1     3     2           3          1         0   \n",
       "394        1        0        1     1     1           1          1         0   \n",
       "\n",
       "     schoolsup  famsup  ...  higher  internet  romantic  famrel  freetime  \\\n",
       "0            1       0  ...       1         0         0       4         3   \n",
       "1            0       1  ...       1         1         0       5         3   \n",
       "2            1       0  ...       1         1         0       4         3   \n",
       "3            0       1  ...       1         1         1       3         2   \n",
       "4            0       1  ...       1         0         0       4         3   \n",
       "..         ...     ...  ...     ...       ...       ...     ...       ...   \n",
       "390          0       1  ...       1         0         0       5         5   \n",
       "391          0       0  ...       1         1         0       2         4   \n",
       "392          0       0  ...       1         0         0       5         5   \n",
       "393          0       0  ...       1         1         0       4         4   \n",
       "394          0       0  ...       1         1         0       3         2   \n",
       "\n",
       "     goout  Dalc  Walc  health  absences  \n",
       "0        4     1     1       3         6  \n",
       "1        3     1     1       3         4  \n",
       "2        2     2     3       3        10  \n",
       "3        2     1     1       5         2  \n",
       "4        2     1     2       5         4  \n",
       "..     ...   ...   ...     ...       ...  \n",
       "390      4     4     5       4        11  \n",
       "391      5     3     4       2         3  \n",
       "392      3     3     3       3         3  \n",
       "393      1     3     4       5         0  \n",
       "394      3     3     3       5         5  \n",
       "\n",
       "[395 rows x 23 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
